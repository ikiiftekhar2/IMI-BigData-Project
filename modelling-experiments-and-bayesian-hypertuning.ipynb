{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### **Importing Data and previous functions**","metadata":{}},{"cell_type":"code","source":"!pip install gdown \n!gdown https://drive.google.com/file/d/1ZrEg-9708-n1A74kj1GM8-RTUSmcGkxk/view?usp=sharing --fuzzy  \n!wget \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:17.470428Z","iopub.execute_input":"2023-02-26T23:13:17.471439Z","iopub.status.idle":"2023-02-26T23:13:31.426940Z","shell.execute_reply.started":"2023-02-26T23:13:17.471400Z","shell.execute_reply":"2023-02-26T23:13:31.425710Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.6.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mDownloading...\nFrom: https://drive.google.com/uc?id=1ZrEg-9708-n1A74kj1GM8-RTUSmcGkxk\nTo: /kaggle/working/divided_data.p\n100%|█████████████████████████████████████████| 296M/296M [00:01<00:00, 270MB/s]\n--2023-02-26 23:13:31--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: ‘helper_functions.py.1’\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n\n2023-02-26 23:13:31 (48.6 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\ndata_subsets = pickle.load( open( \"divided_data.p\", \"rb\" ) )","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:31.430547Z","iopub.execute_input":"2023-02-26T23:13:31.430892Z","iopub.status.idle":"2023-02-26T23:13:31.756783Z","shell.execute_reply.started":"2023-02-26T23:13:31.430855Z","shell.execute_reply":"2023-02-26T23:13:31.755746Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"encoding_dict = {'RISK': {'high': 0, 'low': 1, 'medium': 2},\n 'COUNTRY_RISK_INCOME': {'High': 0, 'Low': 1, 'Moderate': 2},\n 'OCPTN_NM': {'High': 0, 'Low': 1, 'Moderate': 2},\n 'COUNTRY_RISK_RESIDENCY': {'High': 0, 'Low': 1, 'Moderate': 2}}","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:31.758201Z","iopub.execute_input":"2023-02-26T23:13:31.758898Z","iopub.status.idle":"2023-02-26T23:13:31.764832Z","shell.execute_reply.started":"2023-02-26T23:13:31.758858Z","shell.execute_reply":"2023-02-26T23:13:31.763817Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_data_by_percentage(data_subsets, percentage):\n    key = f\"{percentage}%\"\n    if key in data_subsets:\n        data = data_subsets[key]\n        X_train = data['X_train']\n        y_train = data['y_train']\n        X_test = data['X_test']\n        y_test = data['y_test']\n        X_val = data['X_val']\n        y_val = data['y_val']\n        return X_train, y_train, X_test, y_test, X_val, y_val\n    else:\n        raise ValueError(f\"Percentage {percentage}% not found in data subsets.\")","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:31.767438Z","iopub.execute_input":"2023-02-26T23:13:31.767884Z","iopub.status.idle":"2023-02-26T23:13:31.778849Z","shell.execute_reply.started":"2023-02-26T23:13:31.767849Z","shell.execute_reply":"2023-02-26T23:13:31.777873Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"## Available percentages in integers =  1%, 10%, 50%, 100%\npercentage = 10 # Example Usage for 5%\nX_train, y_train, X_test, y_test, X_val, y_val = get_data_by_percentage(data_subsets, percentage)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:31.780800Z","iopub.execute_input":"2023-02-26T23:13:31.781247Z","iopub.status.idle":"2023-02-26T23:13:31.792113Z","shell.execute_reply.started":"2023-02-26T23:13:31.781213Z","shell.execute_reply":"2023-02-26T23:13:31.791085Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"encoding_dict","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:11:57.635426Z","iopub.status.idle":"2023-02-26T23:11:57.636855Z","shell.execute_reply.started":"2023-02-26T23:11:57.636583Z","shell.execute_reply":"2023-02-26T23:11:57.636610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BAse algortihm - probabilistic - hidden markov model - gaussian mixture model - inference-based models - variational inference - markov random fields Deep learning - ResNet model","metadata":{}},{"cell_type":"code","source":"len(X_train)+ len(X_test) + len(X_val)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:06:19.829428Z","iopub.execute_input":"2023-02-14T06:06:19.829834Z","iopub.status.idle":"2023-02-14T06:06:19.838761Z","shell.execute_reply.started":"2023-02-14T06:06:19.829804Z","shell.execute_reply":"2023-02-14T06:06:19.837845Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"98882"},"metadata":{}}]},{"cell_type":"markdown","source":"**Modelling Experiments**","metadata":{}},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:43:26.278775Z","iopub.execute_input":"2023-02-14T05:43:26.279154Z","iopub.status.idle":"2023-02-14T05:43:26.320450Z","shell.execute_reply.started":"2023-02-14T05:43:26.279116Z","shell.execute_reply":"2023-02-14T05:43:26.319488Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        OCPTN_NM  RES_CNTRY_CA  CNTRY_OF_INCOME_CA  PEP_FL  CASH_SUM_IN  \\\n163178         1             1                   1     0.0      857.329   \n446504         1             1                   1     0.0    28221.000   \n204238         1             1                   1     0.0     3269.847   \n232011         1             1                   1     0.0      247.905   \n75847          0             1                   1     0.0    23112.000   \n...          ...           ...                 ...     ...          ...   \n64319          0             1                   1     0.0    51013.000   \n727366         0             1                   1     0.0    70648.071   \n526556         1             1                   1     0.0      632.445   \n460469         1             1                   1     0.0    72541.000   \n117262         0             1                   1     0.0    68239.000   \n\n        CASH_SUM_OUT  CASH_CNT_OUT  WIRES_SUM_IN  WIRES_CNT_IN  WIRES_SUM_OUT  \\\n163178      5584.298          24.0       37047.0          32.0         7796.0   \n446504      4002.000          13.0     1103749.0          52.0      1852685.0   \n204238     10339.382          33.0       96884.0          34.0       347977.0   \n232011      2694.198           7.0       39194.0          22.0        18925.0   \n75847      32434.000           7.0     3437827.0         231.0      1363364.0   \n...              ...           ...           ...           ...            ...   \n64319      58789.000          22.0     4855751.0          30.0      1226437.0   \n727366     31795.000          34.0     3463512.0         125.0       758482.0   \n526556      9886.508          25.0      310074.0         127.0       138467.0   \n460469     56218.000          25.0    16445971.0          93.0      4436570.0   \n117262     66606.000          61.0     1861580.0          57.0      1824675.0   \n\n        ...  COUNTRY_RISK_INCOME  COUNTRY_RISK_RESIDENCY  EMAIL_CNT_OUT  \\\n163178  ...                    1                       1            1.0   \n446504  ...                    1                       1            1.0   \n204238  ...                    1                       1            0.0   \n232011  ...                    1                       1            0.0   \n75847   ...                    1                       1            1.0   \n...     ...                  ...                     ...            ...   \n64319   ...                    1                       1            0.0   \n727366  ...                    1                       1            3.0   \n526556  ...                    1                       1            0.0   \n460469  ...                    1                       1            0.0   \n117262  ...                    1                       1            0.0   \n\n        EMAIL_SUM_OUT  EMAIL_CNT_IN  EMAIL_SUM_IN    REL_AGE  REL_ADD_DT  \\\n163178     292.585218           0.0      0.000000  27.139726    6.698630   \n446504    5054.617057           5.0   5906.587901  68.161644   16.531507   \n204238       0.000000           0.0      0.000000  33.786301   15.293151   \n232011       0.000000           0.0      0.000000  43.090411   16.879452   \n75847       83.378063           1.0   1360.233920  74.956164   19.495890   \n...               ...           ...           ...        ...         ...   \n64319        0.000000           0.0      0.000000  60.438356   21.810959   \n727366    4783.029245           0.0      0.000000  56.454795    6.030137   \n526556       0.000000           0.0      0.000000  33.701370   26.997260   \n460469       0.000000           0.0      0.000000  36.830137   17.306849   \n117262       0.000000           1.0   1020.563027  33.909589   14.471233   \n\n        GENDER_Female  GENDER_Male  \n163178              0            1  \n446504              1            0  \n204238              1            0  \n232011              0            1  \n75847               1            0  \n...               ...          ...  \n64319               1            0  \n727366              1            0  \n526556              0            1  \n460469              1            0  \n117262              1            0  \n\n[6328 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OCPTN_NM</th>\n      <th>RES_CNTRY_CA</th>\n      <th>CNTRY_OF_INCOME_CA</th>\n      <th>PEP_FL</th>\n      <th>CASH_SUM_IN</th>\n      <th>CASH_SUM_OUT</th>\n      <th>CASH_CNT_OUT</th>\n      <th>WIRES_SUM_IN</th>\n      <th>WIRES_CNT_IN</th>\n      <th>WIRES_SUM_OUT</th>\n      <th>...</th>\n      <th>COUNTRY_RISK_INCOME</th>\n      <th>COUNTRY_RISK_RESIDENCY</th>\n      <th>EMAIL_CNT_OUT</th>\n      <th>EMAIL_SUM_OUT</th>\n      <th>EMAIL_CNT_IN</th>\n      <th>EMAIL_SUM_IN</th>\n      <th>REL_AGE</th>\n      <th>REL_ADD_DT</th>\n      <th>GENDER_Female</th>\n      <th>GENDER_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>163178</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>857.329</td>\n      <td>5584.298</td>\n      <td>24.0</td>\n      <td>37047.0</td>\n      <td>32.0</td>\n      <td>7796.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>292.585218</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.139726</td>\n      <td>6.698630</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>446504</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>28221.000</td>\n      <td>4002.000</td>\n      <td>13.0</td>\n      <td>1103749.0</td>\n      <td>52.0</td>\n      <td>1852685.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>5054.617057</td>\n      <td>5.0</td>\n      <td>5906.587901</td>\n      <td>68.161644</td>\n      <td>16.531507</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>204238</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3269.847</td>\n      <td>10339.382</td>\n      <td>33.0</td>\n      <td>96884.0</td>\n      <td>34.0</td>\n      <td>347977.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>33.786301</td>\n      <td>15.293151</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>232011</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>247.905</td>\n      <td>2694.198</td>\n      <td>7.0</td>\n      <td>39194.0</td>\n      <td>22.0</td>\n      <td>18925.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>43.090411</td>\n      <td>16.879452</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>75847</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>23112.000</td>\n      <td>32434.000</td>\n      <td>7.0</td>\n      <td>3437827.0</td>\n      <td>231.0</td>\n      <td>1363364.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>83.378063</td>\n      <td>1.0</td>\n      <td>1360.233920</td>\n      <td>74.956164</td>\n      <td>19.495890</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64319</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>51013.000</td>\n      <td>58789.000</td>\n      <td>22.0</td>\n      <td>4855751.0</td>\n      <td>30.0</td>\n      <td>1226437.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>60.438356</td>\n      <td>21.810959</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>727366</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>70648.071</td>\n      <td>31795.000</td>\n      <td>34.0</td>\n      <td>3463512.0</td>\n      <td>125.0</td>\n      <td>758482.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>4783.029245</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>56.454795</td>\n      <td>6.030137</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>526556</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>632.445</td>\n      <td>9886.508</td>\n      <td>25.0</td>\n      <td>310074.0</td>\n      <td>127.0</td>\n      <td>138467.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>33.701370</td>\n      <td>26.997260</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>460469</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>72541.000</td>\n      <td>56218.000</td>\n      <td>25.0</td>\n      <td>16445971.0</td>\n      <td>93.0</td>\n      <td>4436570.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>36.830137</td>\n      <td>17.306849</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>117262</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>68239.000</td>\n      <td>66606.000</td>\n      <td>61.0</td>\n      <td>1861580.0</td>\n      <td>57.0</td>\n      <td>1824675.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1020.563027</td>\n      <td>33.909589</td>\n      <td>14.471233</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6328 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:54.593166Z","iopub.execute_input":"2023-02-14T05:08:54.593512Z","iopub.status.idle":"2023-02-14T05:08:55.011910Z","shell.execute_reply.started":"2023-02-14T05:08:54.593457Z","shell.execute_reply":"2023-02-14T05:08:55.010697Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"scaler.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.013182Z","iopub.execute_input":"2023-02-14T05:08:55.013468Z","iopub.status.idle":"2023-02-14T05:08:55.051746Z","shell.execute_reply.started":"2023-02-14T05:08:55.013444Z","shell.execute_reply":"2023-02-14T05:08:55.050392Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"MinMaxScaler()"},"metadata":{}}]},{"cell_type":"code","source":"X_train_normal = scaler.transform(X_train)\nX_test_normal = scaler.transform(X_test)\nX_val_normal = scaler.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.053033Z","iopub.execute_input":"2023-02-14T05:08:55.053351Z","iopub.status.idle":"2023-02-14T05:08:55.107227Z","shell.execute_reply.started":"2023-02-14T05:08:55.053323Z","shell.execute_reply":"2023-02-14T05:08:55.105719Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"len(X_train_normal)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.108727Z","iopub.execute_input":"2023-02-14T05:08:55.109076Z","iopub.status.idle":"2023-02-14T05:08:55.115516Z","shell.execute_reply.started":"2023-02-14T05:08:55.109044Z","shell.execute_reply":"2023-02-14T05:08:55.114403Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"316422"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Naive Bayes Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.117657Z","iopub.execute_input":"2023-02-14T05:08:55.118022Z","iopub.status.idle":"2023-02-14T05:08:55.178884Z","shell.execute_reply.started":"2023-02-14T05:08:55.117992Z","shell.execute_reply":"2023-02-14T05:08:55.177458Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = MultinomialNB()\nmodel.fit(X_train_normal, y_train)\n\n# Evaluate the model on the test and validation sets\ntest_predictions = model.predict(X_test)\nval_predictions = model.predict(X_val)\n\ntest_accuracy = accuracy_score(y_test, test_predictions)\nval_accuracy = accuracy_score(y_val, val_predictions)\n\nprint(\"Test Accuracy:\", test_accuracy)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.183123Z","iopub.execute_input":"2023-02-14T05:08:55.183513Z","iopub.status.idle":"2023-02-14T05:08:55.278658Z","shell.execute_reply.started":"2023-02-14T05:08:55.183460Z","shell.execute_reply":"2023-02-14T05:08:55.277802Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.3497198681256447\nValidation Accuracy: 0.3509468308345764\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train_normal, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.282363Z","iopub.execute_input":"2023-02-14T05:08:55.284350Z","iopub.status.idle":"2023-02-14T05:08:55.442319Z","shell.execute_reply.started":"2023-02-14T05:08:55.284310Z","shell.execute_reply":"2023-02-14T05:08:55.441222Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"KNeighborsClassifier()"},"metadata":{}}]},{"cell_type":"code","source":"val_predictions = knn.predict(X_val)\nval_accuracy = accuracy_score(y_val, val_predictions)\nprint(\"Validation Accuracy:\", val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:08:55.443342Z","iopub.execute_input":"2023-02-14T05:08:55.443584Z","iopub.status.idle":"2023-02-14T05:13:41.087036Z","shell.execute_reply.started":"2023-02-14T05:08:55.443561Z","shell.execute_reply":"2023-02-14T05:13:41.085539Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_26/1691949371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    757\u001b[0m                     \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 )\n\u001b[1;32m    761\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \"\"\"\n\u001b[1;32m    633\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"val_predictions = knn.predict(X_test)\nval_accuracy = accuracy_score(y_test, val_predictions)\nprint(\"Test Data Accuracy:\", val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.088477Z","iopub.status.idle":"2023-02-14T05:13:41.089015Z","shell.execute_reply.started":"2023-02-14T05:13:41.088848Z","shell.execute_reply":"2023-02-14T05:13:41.088865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Basic Tensorflow Model**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.089725Z","iopub.status.idle":"2023-02-14T05:13:41.090269Z","shell.execute_reply.started":"2023-02-14T05:13:41.090111Z","shell.execute_reply":"2023-02-14T05:13:41.090128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((X_train_normal,y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test_normal,y_test))\n     \nval_dataset = tf.data.Dataset.from_tensor_slices((X_val_normal,y_val))\n     \n\ntrain_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\nval_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)   ","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.091155Z","iopub.status.idle":"2023-02-14T05:13:41.091643Z","shell.execute_reply.started":"2023-02-14T05:13:41.091494Z","shell.execute_reply":"2023-02-14T05:13:41.091510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_normal.shape[1],)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.092615Z","iopub.status.idle":"2023-02-14T05:13:41.093149Z","shell.execute_reply.started":"2023-02-14T05:13:41.093004Z","shell.execute_reply":"2023-02-14T05:13:41.093019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                         steps_per_epoch = int(0.01*len(train_dataset)),\n                         epochs = 21,\n                         validation_data = val_dataset,\n                         validation_steps = int(0.01*len(val_dataset)), verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.094001Z","iopub.status.idle":"2023-02-14T05:13:41.094431Z","shell.execute_reply.started":"2023-02-14T05:13:41.094285Z","shell.execute_reply":"2023-02-14T05:13:41.094299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.095367Z","iopub.status.idle":"2023-02-14T05:13:41.095838Z","shell.execute_reply.started":"2023-02-14T05:13:41.095673Z","shell.execute_reply":"2023-02-14T05:13:41.095692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.097197Z","iopub.status.idle":"2023-02-14T05:13:41.097792Z","shell.execute_reply.started":"2023-02-14T05:13:41.097529Z","shell.execute_reply":"2023-02-14T05:13:41.097553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.098822Z","iopub.status.idle":"2023-02-14T05:13:41.099187Z","shell.execute_reply.started":"2023-02-14T05:13:41.099005Z","shell.execute_reply":"2023-02-14T05:13:41.099022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**HMM Models**","metadata":{}},{"cell_type":"code","source":"from hmmlearn import hmm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nx_train = X_train.values\n#y_train = y_train.values\nx_test = X_test.values\n#y_test = y_test.values\nx_val = X_val.values\n#y_val = y_val.values\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nx_val = scaler.transform(x_val)\n\n# fit the hidden Markov model using the train data\nn_states = 3\nmodel = hmm.MultinomialHMM( n_iter=100)\nmodel.fit(x_train, np.reshape(y_train,[len(y_train),1]))\n\n# evaluate the model on the test and validation data\ny_test_pred = model.predict(x_test)\ny_val_pred = model.predict(x_val)\n\n# calculate accuracy, precision, recall, and F1 score\naccuracy_test = accuracy_score(y_test, y_test_pred)\nprecision_test = precision_score(y_test, y_test_pred, average='weighted')\nrecall_test = recall_score(y_test, y_test_pred, average='weighted')\nf1_test = f1_score(y_test, y_test_pred, average='weighted')\n\naccuracy_val = accuracy_score(y_val, y_val_pred)\nprecision_val = precision_score(y_val, y_val_pred, average='weighted')\nrecall_val = recall_score(y_val, y_val_pred, average='weighted')\nf1_val = f1_score(y_val, y_val_pred, average='weighted')\n\n# print the evaluation results\nprint(\"Test Accuracy:\", accuracy_test)\nprint(\"Test Precision:\", precision_test)\nprint(\"Test Recall:\", recall_test)\nprint(\"Test F1 Score:\", f1_test)\n\nprint(\"Validation Accuracy:\", accuracy_val)\nprint(\"Validation Precision:\", precision_val)\nprint(\"Validation Recall:\", recall_val)\nprint(\"Validation F1 Score:\", f1_val)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.101407Z","iopub.status.idle":"2023-02-14T05:13:41.101790Z","shell.execute_reply.started":"2023-02-14T05:13:41.101630Z","shell.execute_reply":"2023-02-14T05:13:41.101647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.103418Z","iopub.status.idle":"2023-02-14T05:13:41.103772Z","shell.execute_reply.started":"2023-02-14T05:13:41.103617Z","shell.execute_reply":"2023-02-14T05:13:41.103632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.105707Z","iopub.status.idle":"2023-02-14T05:13:41.106362Z","shell.execute_reply.started":"2023-02-14T05:13:41.105967Z","shell.execute_reply":"2023-02-14T05:13:41.105986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.107755Z","iopub.status.idle":"2023-02-14T05:13:41.108166Z","shell.execute_reply.started":"2023-02-14T05:13:41.107993Z","shell.execute_reply":"2023-02-14T05:13:41.108011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest Algorithm**","metadata":{}},{"cell_type":"markdown","source":"1% of data","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the classifier on the training data\nclf.fit(X_train, y_train)\n\n# Use the trained classifier to make predictions on the validation data\nval_predictions = clf.predict(X_val)\n\n# Evaluate the accuracy of the classifier on the validation data\naccuracy = (val_predictions == y_val).mean()\nprint(\"Validation accuracy:\", accuracy)\n\n# Use the trained classifier to make predictions on the test data\ntest_predictions = clf.predict(X_test)\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Generate a classification report for the validation data\nprint(classification_report(y_val, val_predictions))\n\n# Generate a confusion matrix for the validation data\nprint(confusion_matrix(y_val, val_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.109437Z","iopub.status.idle":"2023-02-14T05:13:41.109793Z","shell.execute_reply.started":"2023-02-14T05:13:41.109641Z","shell.execute_reply":"2023-02-14T05:13:41.109656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"10% of Data","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the classifier on the training data\nclf.fit(X_train, y_train)\n\n# Use the trained classifier to make predictions on the validation data\nval_predictions = clf.predict(X_val)\n\n# Evaluate the accuracy of the classifier on the validation data\naccuracy = (val_predictions == y_val).mean()\nprint(\"Validation accuracy:\", accuracy)\n\n# Use the trained classifier to make predictions on the test data\ntest_predictions = clf.predict(X_test)\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Generate a classification report for the validation data\nprint(classification_report(y_val, val_predictions))\n\n# Generate a confusion matrix for the validation data\nprint(confusion_matrix(y_val, val_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.110716Z","iopub.status.idle":"2023-02-14T05:13:41.111035Z","shell.execute_reply.started":"2023-02-14T05:13:41.110886Z","shell.execute_reply":"2023-02-14T05:13:41.110901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"50%","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the classifier on the training data\nclf.fit(X_train, y_train)\n\n# Use the trained classifier to make predictions on the validation data\nval_predictions = clf.predict(X_val)\n\n# Evaluate the accuracy of the classifier on the validation data\naccuracy = (val_predictions == y_val).mean()\nprint(\"Validation accuracy:\", accuracy)\n\n# Use the trained classifier to make predictions on the test data\ntest_predictions = clf.predict(X_test)\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Generate a classification report for the validation data\nprint(classification_report(y_val, val_predictions))\n\n# Generate a confusion matrix for the validation data\nprint(confusion_matrix(y_val, val_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:13:41.112634Z","iopub.status.idle":"2023-02-14T05:13:41.112962Z","shell.execute_reply.started":"2023-02-14T05:13:41.112802Z","shell.execute_reply":"2023-02-14T05:13:41.112816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gradient Boosting**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:09:00.734266Z","iopub.execute_input":"2023-02-14T06:09:00.734862Z","iopub.status.idle":"2023-02-14T06:09:01.310332Z","shell.execute_reply.started":"2023-02-14T06:09:00.734825Z","shell.execute_reply":"2023-02-14T06:09:01.309388Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"clf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    missing=-999,\n    random_state=2019,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale the data using StandardScaler\npercentage = 1 # Example Usage for 5%\nX_train, y_train, X_test, y_test, X_val, y_val = get_data_by_percentage(data_subsets, percentage)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)\ny_test = le.fit_transform(y_test)\ny_val = le.fit_transform(y_val)\n\n\n# normalize the data using MinMaxScaler\nnormalizer = MinMaxScaler()\nX_train = normalizer.fit_transform(X_train)\nX_val = normalizer.transform(X_val)\nX_test = normalizer.transform(X_test)\n\n# divide the training data into batches\nbatch_size = 128\nnum_batches = len(X_train) // batch_size\nX_train_batches = np.array_split(X_train, num_batches)\ny_train_batches = np.array_split(y_train, num_batches)\n\n# define the XGBoost model\nmodel = xgb.XGBClassifier(    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.1,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    objective = \"multi:softmax\",\n    verbosity = 0,\n    booster = 'gbtree',\n    tree_method='gpu_hist')\n\n# train the model on the training set and validate on the validation set\ntrain_accuracy = []\nval_accuracy = []\ntrain_loss = []\nval_loss = []\nfor epoch in range(10):\n    # randomize the order of the training data\n    permutation = np.random.permutation(num_batches)\n    X_train_batches = [X_train_batches[i] for i in permutation]\n    y_train_batches = [y_train_batches[i] for i in permutation]\n    \n    epoch_train_accuracy = []\n    epoch_train_loss = []\n    for i in range(num_batches):\n        # train the model on each batch\n        model.fit(X_train_batches[i], y_train_batches[i])\n        \n        # calculate the accuracy and loss on the training set\n        y_train_pred = model.predict(X_train_batches[i])\n        train_accuracy_batch = accuracy_score(y_train_batches[i], y_train_pred)\n        epoch_train_accuracy.append(train_accuracy_batch)\n\n    \n    # calculate the accuracy and loss on the validation set\n    y_val_pred = model.predict(X_val)\n    val_accuracy_batch = accuracy_score(y_val, y_val_pred)\n    val_accuracy.append(val_accuracy_batch)\n    \n    epoch_train_accuracy = np.mean(epoch_train_accuracy)\n    train_accuracy.append(epoch_train_accuracy)\n    print(f\"Epoch {epoch}: Train accuracy: {epoch_train_accuracy:.4f}, Val accuracy: {val_accuracy_batch:.4f}\")\n\n# evaluate the model on the testing set\ny_test_pred = model.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nclass_report = classification_report(y_test, y_test_pred)\n\ny_test_pred = model.predict(X_train)\ntest_accuracy = accuracy_score(y_train, y_test_pred)\nconf_matrix = confusion_matrix(y_train, y_test_pred)\nclass_report = classification_report(y_train, y_test_pred)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:27:06.309153Z","iopub.execute_input":"2023-02-14T06:27:06.309512Z","iopub.status.idle":"2023-02-14T06:32:41.153740Z","shell.execute_reply.started":"2023-02-14T06:27:06.309480Z","shell.execute_reply":"2023-02-14T06:32:41.152690Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 0: Train accuracy: 1.0000, Val accuracy: 0.9229\nEpoch 1: Train accuracy: 1.0000, Val accuracy: 0.9260\nEpoch 2: Train accuracy: 1.0000, Val accuracy: 0.9115\nEpoch 3: Train accuracy: 1.0000, Val accuracy: 0.9248\nEpoch 4: Train accuracy: 1.0000, Val accuracy: 0.9241\nEpoch 5: Train accuracy: 1.0000, Val accuracy: 0.9260\nEpoch 6: Train accuracy: 1.0000, Val accuracy: 0.9235\nEpoch 7: Train accuracy: 1.0000, Val accuracy: 0.9109\nEpoch 8: Train accuracy: 1.0000, Val accuracy: 0.9185\nEpoch 9: Train accuracy: 1.0000, Val accuracy: 0.9336\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print evaluation metrics\nprint(f\"\\nTest accuracy: {test_accuracy:.4f}\")\nprint(f\"Test loss: {test_loss:.4f}\"\nprint(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\nprint(f\"\\nClassification Report:\\n{class_report}\")\n\n# Plot epoch vs accuracy graph for training and validation sets\nplt.plot(range(1, len(train_accuracy)+1), train_accuracy, label=\"Training\")\nplt.plot(range(1, len(val_accuracy)+1), val_accuracy, label=\"Validation\")\nplt.title(\"Epoch vs Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()\n\n# Plot epoch vs loss graph for training and validation sets\nplt.plot(range(1, len(train_loss)+1), train_loss, label=\"Training\")\nplt.plot(range(1, len(val_loss)+1), val_loss, label=\"Validation\")\nplt.title(\"Epoch vs Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\nThis will generate two graphs: one showing epoch vs accuracy for the training and validation sets, and another showing epoch vs loss for the training and validation sets.\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:51:27.853576Z","iopub.status.idle":"2023-02-14T05:51:27.856471Z","shell.execute_reply.started":"2023-02-14T05:51:27.856268Z","shell.execute_reply":"2023-02-14T05:51:27.856289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:34.113405Z","iopub.execute_input":"2023-02-26T23:13:34.114092Z","iopub.status.idle":"2023-02-26T23:13:34.147809Z","shell.execute_reply.started":"2023-02-26T23:13:34.114054Z","shell.execute_reply":"2023-02-26T23:13:34.146361Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nimport sklearn","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:34.328482Z","iopub.execute_input":"2023-02-26T23:13:34.329098Z","iopub.status.idle":"2023-02-26T23:13:34.808230Z","shell.execute_reply.started":"2023-02-26T23:13:34.329062Z","shell.execute_reply":"2023-02-26T23:13:34.807274Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import pickle\ndata_subsets = pickle.load( open( \"divided_data.p\", \"rb\" ) )","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:34.810441Z","iopub.execute_input":"2023-02-26T23:13:34.810820Z","iopub.status.idle":"2023-02-26T23:13:35.123017Z","shell.execute_reply.started":"2023-02-26T23:13:34.810784Z","shell.execute_reply":"2023-02-26T23:13:35.121727Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"encoding_dict = {'RISK': {'high': 0, 'low': 1, 'medium': 2},\n 'COUNTRY_RISK_INCOME': {'High': 0, 'Low': 1, 'Moderate': 2},\n 'OCPTN_NM': {'High': 0, 'Low': 1, 'Moderate': 2},\n 'COUNTRY_RISK_RESIDENCY': {'High': 0, 'Low': 1, 'Moderate': 2}}","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:35.124856Z","iopub.execute_input":"2023-02-26T23:13:35.125307Z","iopub.status.idle":"2023-02-26T23:13:35.131232Z","shell.execute_reply.started":"2023-02-26T23:13:35.125269Z","shell.execute_reply":"2023-02-26T23:13:35.130134Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## Available percentages in integers =  1%, 10%, 50%, 100%\npercentage = 50 # Example Usage for 5%\nX_train, y_train, X_test, y_test, X_val, y_val = get_data_by_percentage(data_subsets, percentage)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:35.697188Z","iopub.execute_input":"2023-02-26T23:13:35.697585Z","iopub.status.idle":"2023-02-26T23:13:35.702654Z","shell.execute_reply.started":"2023-02-26T23:13:35.697546Z","shell.execute_reply":"2023-02-26T23:13:35.701485Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor, DMatrix, XGBClassifier\n\n# Model selection\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n# Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer\n\n# Skopt functions\nfrom skopt import BayesSearchCV\nfrom skopt.callbacks import DeadlineStopper, DeltaYStopper\nfrom skopt.space import Real, Categorical, Integer","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:36.453828Z","iopub.execute_input":"2023-02-26T23:13:36.458779Z","iopub.status.idle":"2023-02-26T23:13:36.902857Z","shell.execute_reply.started":"2023-02-26T23:13:36.458728Z","shell.execute_reply":"2023-02-26T23:13:36.901749Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:37.049165Z","iopub.execute_input":"2023-02-26T23:13:37.049557Z","iopub.status.idle":"2023-02-26T23:13:37.064748Z","shell.execute_reply.started":"2023-02-26T23:13:37.049521Z","shell.execute_reply":"2023-02-26T23:13:37.063889Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n    \"\"\"\n    A wrapper for measuring time and performances of different optmizers\n    \n    optimizer = a sklearn or a skopt optimizer\n    X = the training set \n    y = our target\n    title = a string label for the experiment\n    \"\"\"\n    start = time()\n    \n    if callbacks is not None:\n        optimizer.fit(X, y, callback=callbacks)\n    else:\n        optimizer.fit(X, y)\n        \n    d=pd.DataFrame(optimizer.cv_results_)\n    best_score = optimizer.best_score_\n    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n    best_params = optimizer.best_params_\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:37.595455Z","iopub.execute_input":"2023-02-26T23:13:37.596383Z","iopub.status.idle":"2023-02-26T23:13:37.602927Z","shell.execute_reply.started":"2023-02-26T23:13:37.596343Z","shell.execute_reply":"2023-02-26T23:13:37.601810Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_stratified = pd.cut(y_train.rank(method='first'), bins=10, labels=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:38.221235Z","iopub.execute_input":"2023-02-26T23:13:38.221968Z","iopub.status.idle":"2023-02-26T23:13:38.263328Z","shell.execute_reply.started":"2023-02-26T23:13:38.221930Z","shell.execute_reply":"2023-02-26T23:13:38.262235Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"scoring = make_scorer(partial(mean_squared_error, squared=False), \n                      greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:38.715799Z","iopub.execute_input":"2023-02-26T23:13:38.716402Z","iopub.status.idle":"2023-02-26T23:13:38.721343Z","shell.execute_reply.started":"2023-02-26T23:13:38.716366Z","shell.execute_reply":"2023-02-26T23:13:38.720067Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from scipy.stats.mstats import winsorize\ny_train = np.array(winsorize(y_train, [0.002, 0.0]))","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:39.243547Z","iopub.execute_input":"2023-02-26T23:13:39.244302Z","iopub.status.idle":"2023-02-26T23:13:39.258416Z","shell.execute_reply.started":"2023-02-26T23:13:39.244259Z","shell.execute_reply":"2023-02-26T23:13:39.257470Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=7,\n                      shuffle=True, \n                      random_state=0)\n\ncv_strategy = list(skf.split(X_train, y_stratified))","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:39.768884Z","iopub.execute_input":"2023-02-26T23:13:39.769253Z","iopub.status.idle":"2023-02-26T23:13:39.843737Z","shell.execute_reply.started":"2023-02-26T23:13:39.769222Z","shell.execute_reply":"2023-02-26T23:13:39.842577Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"reg = XGBClassifier(random_state=0, verbosity = 0, booster='gbtree', objective='multi:softmax', tree_method='gpu_hist', num_class = 3)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:13:40.333893Z","iopub.execute_input":"2023-02-26T23:13:40.334276Z","iopub.status.idle":"2023-02-26T23:13:40.339123Z","shell.execute_reply.started":"2023-02-26T23:13:40.334232Z","shell.execute_reply":"2023-02-26T23:13:40.338177Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"search_spaces = {'learning_rate': Real(0.01, 1.0, 'uniform'),\n                 'max_depth': Integer(2, 12),\n                 'subsample': Real(0.1, 1.0, 'uniform'),\n                 'colsample_bytree': Real(0.1, 1.0, 'uniform'), # subsample ratio of columns by tree\n                 'reg_lambda': Real(1e-9, 100., 'uniform'), # L2 regularization\n                 'reg_alpha': Real(1e-9, 100., 'uniform'), # L1 regularization\n                 'n_estimators': Integer(50, 5000)\n   }","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:14:25.159933Z","iopub.execute_input":"2023-02-26T23:14:25.160312Z","iopub.status.idle":"2023-02-26T23:14:25.171382Z","shell.execute_reply.started":"2023-02-26T23:14:25.160280Z","shell.execute_reply":"2023-02-26T23:14:25.170445Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"opt = BayesSearchCV(estimator=reg,                                    \n                    search_spaces=search_spaces,                      \n                    scoring=scoring,                                  \n                    cv=cv_strategy,                                           \n                    n_iter=120,                                       # max number of trials\n                    n_points=1,                                       # number of hyperparameter sets evaluated at the same time\n                    n_jobs=1,                                         # number of jobs\n                    iid=False,                                        # if not iid it optimizes on the cv score\n                    return_train_score=False,                         \n                    refit=False,                                      \n                    optimizer_kwargs={'base_estimator': 'GP'},        # optmizer parameters: we use Gaussian Process (GP)\n                    random_state=0)  ","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:14:28.086310Z","iopub.execute_input":"2023-02-26T23:14:28.087111Z","iopub.status.idle":"2023-02-26T23:14:28.096337Z","shell.execute_reply.started":"2023-02-26T23:14:28.087069Z","shell.execute_reply":"2023-02-26T23:14:28.095061Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/skopt/searchcv.py:300: UserWarning: The `iid` parameter has been deprecated and will be ignored.\n  warnings.warn(\"The `iid` parameter has been deprecated \"\n","output_type":"stream"}]},{"cell_type":"code","source":"overdone_control = DeltaYStopper(delta=0.0001)                    # We stop if the gain of the optimization becomes too small\ntime_limit_control = DeadlineStopper(total_time=60*101)          # We impose a time limit (7 hours)\n\nbest_params = report_perf(opt, X_train, y_train,'XGBoost_regression', \n                          callbacks=[overdone_control, time_limit_control])","metadata":{"execution":{"iopub.status.busy":"2023-02-26T23:14:35.387360Z","iopub.execute_input":"2023-02-26T23:14:35.387952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overdone_control = DeltaYStopper(delta=0.0001)                    # We stop if the gain of the optimization becomes too small\ntime_limit_control = DeadlineStopper(total_time=60*15)          # We impose a time limit (7 hours)\n\nbest_params = report_perf(opt, X_train, y_train,'XGBoost_regression', \n                          callbacks=[overdone_control, time_limit_control])","metadata":{"execution":{"iopub.status.busy":"2023-02-26T18:05:54.883087Z","iopub.execute_input":"2023-02-26T18:05:54.883475Z","iopub.status.idle":"2023-02-26T18:20:08.841470Z","shell.execute_reply.started":"2023-02-26T18:05:54.883442Z","shell.execute_reply":"2023-02-26T18:20:08.838783Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"XGBoost_regression took 853.95 seconds,  candidates checked: 37, best CV score: -0.393 ± 0.027\nBest parameters:\nOrderedDict([('colsample_bytree', 0.6889972247625309),\n             ('learning_rate', 0.6550183688621571),\n             ('max_depth', 7),\n             ('n_estimators', 50),\n             ('reg_alpha', 1e-09),\n             ('reg_lambda', 100.0),\n             ('subsample', 0.2762194154869853)])\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"50%","metadata":{}},{"cell_type":"code","source":"print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n        + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n                                len(optimizer.cv_results_['params']),\n                                best_score,\n                                best_score_std))    \nprint('Best parameters:')\npprint.pprint(best_params)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}